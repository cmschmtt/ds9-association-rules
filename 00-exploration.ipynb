{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "987db42f-feb2-4ef1-bf66-0f0f564bd0ef",
   "metadata": {},
   "source": [
    "# 0. Exploration\n",
    "\n",
    "In this notebook we walk through the process for processing the script text files.\n",
    "\n",
    "---\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78ea0a43-6f59-4927-b3b5-fce3d98e86c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8cd467f-f30d-4dfd-99d8-e2915953a068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files\n",
    "with open('scripts/404.txt') as f:\n",
    "    ep = f.read()\n",
    "    \n",
    "ep_lines = ep.split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fccb84e-66ce-4461-9b65-08accad20f7f",
   "metadata": {},
   "source": [
    "### TV scripts\n",
    "\n",
    "We're working with a collection of .txt script files from a fansite. I suspect these were maybe scanned and OCR processed based off of scriptbook compendiums, but I'm not certain. Later we'll find some typos and formatting errors. Here's what the first thousand characters of the episode \"Past Prologue\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4568ceca-a600-4654-b31e-8a7d411f356f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                  STAR TREK: DEEP SPACE NINE \n",
      "                              \n",
      "                        \"Past Prologue\" \n",
      "                          #40511-404 \n",
      "                              \n",
      "                           Story by \n",
      "                        Kathryn Powers \n",
      "                              \n",
      "                          Teleplay by \n",
      "                      Peter Allan Fields \n",
      "                              \n",
      "                          Directed by \n",
      "                          Rick Kolbe \n",
      "\n",
      "THE WRITING CREDITS MAY NOT BE FINAL AND SHOULD NOT BE USED \n",
      "FOR PUBLICITY OR ADVERTISING PURPOSES WITHOUT FIRST CHECKING \n",
      "WITH THE TELEVISION LEGAL DEPARTMENT.\n",
      "\n",
      "Copyright 1992 Paramount Pictures Corporation. All Rights \n",
      "Reserved. This script is not for publication or \n",
      "reproduction. No one is authorized to dispose of same. If \n",
      "lost or destroyed, please notify the Script Department.\n",
      "\n",
      "Return to Script Department             FINAL DRAFT\n",
      "PARAMOUNT PICTURES CORPORATION\n",
      "                        OCTOBER 5, 1992\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(ep[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb69b8f-ad87-4acc-882d-752dffa61367",
   "metadata": {},
   "source": [
    "Every TV script file is formatted this way -- the .txt file begins with an informational header. We're gong to be datamining character association rules, and much of the information in the header will be irrelevant. Let's proceed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddf9d62d-6c7d-4326-8b38-d979a184edf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   STAR TREK: DS9   \"Past Prologue\"\t10/05/92 - CAST\n",
      "\n",
      "                  STAR TREK: DEEP SPACE NINE \n",
      "                        \"Past Prologue\" \n",
      "                            CAST\n",
      "\n",
      "                BENJAMIN SISKO     GARAK\n",
      "                MILES O'BRIEN      TAHNA\n",
      "                KIRA               GUL DANAR,\n",
      "                ODO                ADMIRAL\n",
      "                BASHIR             B'ETOR\n",
      "                DAX                LURSA\n",
      "                                   BAJORAN DEPUTY\n",
      "                                   GUL DUKAT\n",
      "                                   NORIC\n",
      "                                   RAKA\n",
      "                Non-speaking       \n",
      "                BAJORAN N.D. MEDICAL ASSISTANTS\n",
      "                N.D. SUPERNUMARIES \n",
      "\n",
      "      STAR TREK: DS9 - \"Past Prologue\" - 10/05/92 - SETS \n",
      "\n",
      "                  STAR TREK: DEEP SPACE NINE \n",
      "                        \"Past Prologue\" \n",
      "                             SETS \n",
      "\n",
      "        INTERIORS                     EXTERIORS\n",
      "        DEEP SPACE NINE                 DEEP SPACE NINE\n",
      "          PROMENADE (REPLIMAT)          \n",
      "          OPS                           RUNABOUT YANGTZEE\n",
      "          TRANSPORTER PAD               \n",
      "          MAIN VIEWSCREEN               RUNABOUT GANGES\n",
      "           (CARDASSIAN BRIDGE)\n",
      "          INFIRMARY                     WORMHOLE\n",
      "          KIRA'S QUARTERS               \n",
      "          COMMANDER'S OFFICE            \n",
      "          SISKO'S OFFICE                \n",
      "          SECURITY OFFICE               \n",
      "          QUARK'S                       \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(ep[1000:2500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebe20d3-599a-44b4-8751-30c0d3ee47ba",
   "metadata": {},
   "source": [
    "After the informational header, every script contains yet more information: the full cast, and the sets necessary for the episode.\n",
    "\n",
    "The full cast list could be useful if we were looking for episode-based association rules, but, per previous work, it's likely that episode-based association rules will be too generic.\n",
    "\n",
    "Below we see what the script files look like once characters are speaking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9c679ab-9109-45d0-be51-976b794e1832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      \n",
      "                              \n",
      "\n",
      "            DEEP SPACE: \"Past Prologue\" 10/05/92 - TEASER            1.\n",
      "                  STAR TREK: DEEP SPACE NINE                    \n",
      "\n",
      "                           \"Past Prologue\"                             \n",
      "                            TEASER                              \n",
      "\n",
      "\tFADE IN:\n",
      "\n",
      "1    EXT. SPACE - DS9 (OPTICAL)\n",
      "\n",
      "\tEstablishing.\n",
      "\n",
      "2    INT. PROMENADE REPLIMAT\n",
      "\n",
      "\tDOCTOR JULIAN BASHIR sits enjoying a tea-like beverage, \n",
      "\treading a medical journal PADD... as the large, ever-pleasant \n",
      "\tCardassian, GARAK, interposes himself between Bashir and the \n",
      "\tlatter's view, with:\n",
      "\n",
      "\t\t\t\t\tGARAK\n",
      "\t\t\tIt's Doctor Bashir, isn't it?  Of \n",
      "\t\t\tcourse it is.  May I introduce myself?\n",
      "\n",
      "\tBashir looks up and reacts... and if this were a poker game... \n",
      "\tand in a way, it is... Bashir would be at a severe \n",
      "\tdisadvantage.  His heart's just started thumping - he's been \n",
      "\talerted about this man, never thought he'd come face to face \n",
      "\twith him like this...\n",
      "\n",
      "\t\t\t\t\tBASHIR\n",
      "\t\t\tUh... yes, yes of course.\n",
      "\n",
      "\t\t\t\t\tGARAK\n",
      "\t\t\t\t(sits)\n",
      "\t\t\tMy name is Garak; Cardassian by birth, \n",
      "\t\t\tobviously.  The o\n"
     ]
    }
   ],
   "source": [
    "print(ep[2900:4000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d094f9-9b75-449c-b663-1f521a0ce87c",
   "metadata": {},
   "source": [
    "Note:\n",
    "- Each episode has a Teaser/Act one/Act two/Act 3/Act 4/Act 5 structure. These are indicated in the script, though there are some typos/formatting errors!\n",
    "- Every new physical page is indicated with a header that includes episode title, act, and page number.\n",
    "- Speakers are given by all-caps character names five indents in.\n",
    "- We see action notes such as `(sits)` are indented at four tabs in, but there are larger blocks of exposition as well.\n",
    "\n",
    "Some of this information will be useless, and we'll need to strip it out, and some of this structure will be useful for us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d26806-40ac-476c-bcdd-119dd8f85193",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Cleaning scripts\n",
    "\n",
    "Below are helper scripts useful for extracting information and stripping unneeded lines from the script files. (Note: these scripts are also in `preprocessing.py`.)\n",
    "\n",
    "We extract information like the episode title, and clear lines such as e.g.:\n",
    "\n",
    "```\n",
    "           DEEP SPACE: \"Past Prologue\" 10/05/92 - ACT TWO           24.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3f5de40-7afc-4616-80f9-a056c55c3722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def space_return(num_spaces, ep_lines=ep_lines):\n",
    "    '''\n",
    "    Returns a list of lines that start with num_spaces spaces.\n",
    "    Input must be a list of lines.\n",
    "    '''\n",
    "    # used on lines version of script, not string script\n",
    "    assert type(ep_lines) == list\n",
    "    \n",
    "    def line_starts_with_only_n(line, n=num_spaces):\n",
    "        # helper function to check matches\n",
    "        spaces = ' ' * num_spaces\n",
    "        return (line[:n] == spaces) and (line[n] != ' ')\n",
    "    \n",
    "    return [line for line in ep_lines if line_starts_with_only_n(line)]\n",
    "\n",
    "\n",
    "def tab_return(num_tabs, ep_lines=ep_lines):\n",
    "    '''\n",
    "    Returns a list of lines that start with num_tabs tabs.\n",
    "    Input must be a list of lines.\n",
    "    '''\n",
    "    assert type(ep_lines) == list\n",
    "    \n",
    "    def line_starts_with_only_n(line, n=num_tabs):\n",
    "        # should probably refactor this since the helper fn is\n",
    "        # defined twice while nested... TODO\n",
    "        tabs = '\\t' * num_tabs\n",
    "        return (line[:n] == tabs) and (line[n] != '\\t')\n",
    "    \n",
    "    return [line for line in ep_lines if line_starts_with_only_n(line)]\n",
    "\n",
    "\n",
    "def get_title(s):\n",
    "    '''\n",
    "    Returns from the string version of the script the title\n",
    "    of the episode\n",
    "    '''\n",
    "    \n",
    "    # note: in \"full\" version of this workflow, the compile\n",
    "    # statement is run outside of the function to improve speed\n",
    "    import re\n",
    "    title_finder = re.compile(r'\"(.*)\"')\n",
    "    \n",
    "    # used on string version of episode, not lines script\n",
    "    assert type(s) == str\n",
    "    \n",
    "    return title_finder.search(s).group(1)\n",
    "\n",
    "\n",
    "def get_header_cutoff(ep_lines=ep_lines):\n",
    "    '''\n",
    "    Determines the index cutoff for where the episode header ends.\n",
    "    Input should be a list of strings.\n",
    "    '''\n",
    "    \n",
    "    # used on lines not str\n",
    "    assert type(ep_lines) == list\n",
    "    \n",
    "    cutoff = 0\n",
    "    for ix, line in enumerate(ep_lines):\n",
    "        if line.strip() == 'TEASER':\n",
    "            cutoff = ix\n",
    "            break\n",
    "    return cutoff\n",
    "\n",
    "\n",
    "def match_page_header(line):\n",
    "    '''\n",
    "    This function identifies if a line is a page header.\n",
    "    Input is a single line.\n",
    "    '''\n",
    "    # later eps say DEEP SPACE NINE:\n",
    "    # hopefully this will be more flexible\n",
    "    return (line.strip().startswith('DEEP SPACE')) and (\":\" in line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe56438-f883-4ff5-9b6e-2b33725d67b6",
   "metadata": {},
   "source": [
    "With the above functions defined, we can cut off the header, store the episode title, and keep only relevant lines in the following four lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4628ed17-ce1b-4740-a019-fde663d1e111",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = get_header_cutoff(ep_lines)\n",
    "header = ep_lines[:85]\n",
    "ep_lines = ep_lines[85:]\n",
    "\n",
    "ep_lines = [l for l in ep_lines if not match_page_header(l)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e5848e-7dc7-457a-b4d4-ca796aad6199",
   "metadata": {},
   "source": [
    "Below, let's see what `ep_lines` looks like so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "990dae6b-7172-4e85-9145-31edad6b948c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\t\\t\\t\\t\\tKIRA',\n",
       " '\\t\\t\\tHow is he?',\n",
       " '',\n",
       " '\\t\\t\\t\\t\\tBASHIR',\n",
       " '\\t\\t\\tSecond degree burns, lacerations, a ',\n",
       " '\\t\\t\\tminor concussion... Not much compared ',\n",
       " \"\\t\\t\\tto what he's been through before.\",\n",
       " '',\n",
       " '',\n",
       " '\\t\\t\\t\\t\\tSISKO']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ep_lines[500:510]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da79a334-994d-4ad3-80c3-7f058498f2f8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Splitting into acts\n",
    "\n",
    "Episode-based association rules previously too general to be interesting -- but episode _acts_ are a little more fine-grained.\n",
    "\n",
    "Scene-based association rules would probably be most interesting, but it's difficult to tell the difference between scenes and shots in this dataset (some elaboration below.) Splitting based on acts, however, is reasonably straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd25e5e8-252e-42fb-9696-1679543c6197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def act_partition(ep_lines):\n",
    "    '''\n",
    "    Accepts a list of episode lines.\n",
    "    Returns six lists, one list per act, including the teaser.\n",
    "    '''\n",
    "    \n",
    "    # used on lines not str\n",
    "    assert type(ep_lines) == list\n",
    "        \n",
    "    stripped_lines = [l.strip() for l in ep_lines]\n",
    "    \n",
    "    # locating start of each act:\n",
    "    teaser_begin = stripped_lines.index('TEASER')\n",
    "    act_1_begin = stripped_lines.index('ACT ONE')\n",
    "    act_2_begin = stripped_lines.index('ACT TWO')\n",
    "    act_3_begin = stripped_lines.index('ACT THREE')\n",
    "    act_4_begin = stripped_lines.index('ACT FOUR')\n",
    "    act_5_begin = stripped_lines.index('ACT FIVE')\n",
    "    \n",
    "    # subsetting:\n",
    "    teaser = ep_lines[:act_1_begin]\n",
    "    act_1 = ep_lines[act_1_begin:act_2_begin]\n",
    "    act_2 = ep_lines[act_2_begin:act_3_begin]\n",
    "    act_3 = ep_lines[act_3_begin:act_4_begin]\n",
    "    act_4 = ep_lines[act_4_begin:act_5_begin]\n",
    "    act_5 = ep_lines[act_5_begin:]\n",
    "    \n",
    "    return teaser, act_1, act_2, act_3, act_4, act_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4747129-62d3-49a9-8b45-317b4c97a258",
   "metadata": {},
   "outputs": [],
   "source": [
    "teaser, act_1, act_2, act_3, act_4, act_5 = act_partition(ep_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c69c384-4052-42b6-857f-5efdd09c90f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "acts = [teaser, act_1, act_2, act_3, act_4, act_5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4b128e-e380-4fdb-8ae5-4f0547fc6b07",
   "metadata": {},
   "source": [
    "Below, the act lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9badcd13-31dc-434a-85ef-99cc1f31a717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['                           \"Past Prologue\"                             ',\n",
       " '                            TEASER                              ',\n",
       " '',\n",
       " '\\tFADE IN:',\n",
       " '',\n",
       " '1    EXT. SPACE - DS9 (OPTICAL)',\n",
       " '',\n",
       " '\\tEstablishing.',\n",
       " '',\n",
       " '2    INT. PROMENADE REPLIMAT']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teaser[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7e72033-a638-45d0-a61b-82f2002f1f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['                           ACT FIVE                             ',\n",
       " '',\n",
       " '\\tFADE IN:',\n",
       " '',\n",
       " '59   EXT. SPACE - DEEP SPACE NINE (OPTICAL)',\n",
       " '',\n",
       " '\\tThe Klingon ship is no longer present.',\n",
       " '',\n",
       " '60   INT. OPS',\n",
       " '']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_5[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3c1e23-ee60-4e77-aa30-7de097d3aadc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exploring scenes & shots\n",
    "\n",
    "- in progress\n",
    "- identified a regex\n",
    "- need to handle things like...\n",
    "\n",
    "```\n",
    "2    INT. PROMENADE REPLIMAT\n",
    "2    CONTINUED:\n",
    "2    CONTINUED:\t(2)\n",
    "\n",
    "...\n",
    "\n",
    "26   CONTINUED:\n",
    "27   OMITTED\n",
    "29   OMITTED\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6eba947a-6495-4985-b835-009a51366e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    EXT. SPACE - DS9 (OPTICAL)\n",
      "2    INT. PROMENADE REPLIMAT\n",
      "2    CONTINUED:\n",
      "2    CONTINUED:\t(2)\n",
      "3    INT. OPS\n",
      "4    AT TRANSPORTER PAD (OPTICAL)\n",
      "5    REACTION - KIRA\n",
      "6    RESUME - SHOT\n"
     ]
    }
   ],
   "source": [
    "scene_pattern = '^\\d+\\s.*'\n",
    "\n",
    "for line in teaser:\n",
    "    # scene_pattern = '^\\d+.*'\n",
    "    if re.match(scene_pattern, line):\n",
    "        print(line)\n",
    "\n",
    "def match_scene_continues(line):\n",
    "    pattern = '^\\d+.*'\n",
    "    return (re.match(pattern, line)) and ('CONTINUED:' in line)\n",
    "\n",
    "def match_sub_scene(line):\n",
    "    pattern = '^\\d+\\w+.*'\n",
    "    return re.match(pattern, line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a48ee64e-0334-4683-867e-9412d29051a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _not(func):\n",
    "#     # https://stackoverflow.com/questions/33989155/is-there-a-filter-opposite-builtin\n",
    "#     def not_func(*args, **kwargs):\n",
    "#         return not func(*args, **kwargs)\n",
    "#     return not_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2384128-a2f5-477a-862d-74e91736ad5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "teaser = [l for l in teaser if not match_scene_continues(l)]\n",
    "teaser = [l for l in teaser if not match_sub_scene(l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00162a0c-5868-4091-9d30-d154ecf66bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['                           \"Past Prologue\"                             ',\n",
       " '                            TEASER                              ',\n",
       " '',\n",
       " '\\tFADE IN:',\n",
       " '',\n",
       " '1    EXT. SPACE - DS9 (OPTICAL)',\n",
       " '',\n",
       " '\\tEstablishing.',\n",
       " '',\n",
       " '2    INT. PROMENADE REPLIMAT',\n",
       " '',\n",
       " '\\tDOCTOR JULIAN BASHIR sits enjoying a tea-like beverage, ',\n",
       " '\\treading a medical journal PADD... as the large, ever-pleasant ',\n",
       " '\\tCardassian, GARAK, interposes himself between Bashir and the ',\n",
       " \"\\tlatter's view, with:\"]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teaser[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b49daf49-31e9-4d0b-ac40-bfa026ce41b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scene_pattern = '^\\d+\\s.*'\n",
    "\n",
    "# for line in teaser:\n",
    "#     # scene_pattern = '^\\d+.*'\n",
    "#     if re.match(scene_pattern, line):\n",
    "#         print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d199db9-4347-4cc5-8077-226872bd5ee2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Identifying & cleaning speakers\n",
    "\n",
    "For this analysis we're not interested in _what_ characters say -- just whether they say anything, and who's around when they're saying things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c2be9d9-d434-49ca-a85a-c3832373bb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_speaker(s):\n",
    "    '''\n",
    "    Works on a single string to clear common prefixes and suffixes.\n",
    "    This is not the canonical version of clean_speaker; the version in\n",
    "    preprocessing.py is. #JustNotebookWorkflowThings\n",
    "    '''\n",
    "    \n",
    "    clean_up = ['(V.O.)','(O.S.)', '(OS)', \"'S COM VOICE\",'(MONITOR)','\\'S COMPUTER VOICE',\n",
    "                \"(cont'd)\", \"(Cont'd)\", '(ON SCREEN)', '(0.S.)', '(FAR O.S.)', 'ON SCREEN', \n",
    "               '(Cont,d)', '(O. C.. )', \"(Cont' d)\", \"'S VOICE\", '(0. S. )', ' (0. S.)', ' (0.S)',\n",
    "               \"'S COM VOICE\", \"'S VOICE\", \"'S COMM VOICE\"]\n",
    "    \n",
    "    for each in clean_up:\n",
    "        if each in s:\n",
    "            s = s.replace(each, '')\n",
    "    \n",
    "    s = s.strip()\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fbc055a-c85c-4ca5-a7f0-6ea8dbf7f9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_speakers(lines):\n",
    "    '''\n",
    "    Accepts a list of episode lines.\n",
    "    Returns only the speakers.\n",
    "    '''\n",
    "    raw_speakers = tab_return(5, ep_lines=lines)\n",
    "    raw_speakers = [s.strip() for s in raw_speakers]\n",
    "    raw_speakers = [clean_speaker(s) for s in raw_speakers]\n",
    "    \n",
    "    return raw_speakers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93cb8d7-7b16-4b90-8203-c9c522b6d823",
   "metadata": {},
   "source": [
    "### Generating act-based speaker counts for \"Past Prologue\"\n",
    "\n",
    "In following notebooks, we'll actually extract this information for every episode. Here we see the process.\n",
    "\n",
    "Speaker counts aren't strictly necessary for a priori rules mining... but I'm keeping it in case it's useful for later analysis, and because it's pretty easy to collect with `Counter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e4769d4-f38d-4a43-bef3-9a1c770e9b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict to store speakers & line counts:\n",
    "test_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b750058-7bf9-4cf2-9f73-f69a1c4b7496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"O'BRIEN\", 'SISKO', 'KIRA', 'GARAK', 'BASHIR', 'TAHNA', 'DAX'}\n",
      "\n",
      "{\"O'BRIEN\", 'GUL DANAR', 'KIRA', 'ADMIRAL', 'SISKO', 'BASHIR', 'TAHNA'}\n",
      "\n",
      "{'LURSA', \"B'ETOR\", 'GARAK', 'ODO', 'KIRA', 'BAJORAN DEPUTY', 'SISKO', 'BASHIR', 'TAHNA'}\n",
      "\n",
      "{'LURSA', \"B'ETOR\", 'ODO', 'SISKO', 'KIRA', 'GARAK', 'TAHNA'}\n",
      "\n",
      "{\"B'ETOR\", 'LURSA', 'ODO', '(thru door)', 'SISKO', 'KIRA', '(indicates)', 'GARAK', 'BASHIR'}\n",
      "\n",
      "{'LURSA', \"B'ETOR\", \"O'BRIEN\", 'ODO', 'GUL DANAR', 'KIRA', 'KIANG (OPTICAL)', 'SISKO', 'BASHIR', 'TAHNA', 'DAX'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# note -- something like this would strictly be more efficient, and who knows, if I refactor this I\n",
    "# might shift to just using sets for speed. but I do have the data scientist's delight here -- the privilege\n",
    "# of doing an ad hoc analysis that doesn't need to scale.\n",
    "for act in acts:\n",
    "    print(set(return_speakers(act)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8456effc-5905-469c-b939-d9fe3412e31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GARAK',\n",
       " 'BASHIR',\n",
       " 'GARAK',\n",
       " 'BASHIR',\n",
       " 'BASHIR',\n",
       " 'GARAK',\n",
       " 'BASHIR',\n",
       " 'GARAK',\n",
       " 'BASHIR',\n",
       " 'GARAK',\n",
       " 'BASHIR',\n",
       " 'GARAK',\n",
       " 'BASHIR',\n",
       " 'GARAK',\n",
       " 'BASHIR']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_speakers(teaser)[:15] # here's what it looks like raw..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cecc2b64-5bb3-4001-8ba8-de36afdfb0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Counter to get speakers & counts per act\n",
    "speakers = Counter(return_speakers(teaser))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2fcd2fe2-bda5-4efa-84e3-edce0062f289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the test dict\n",
    "# right now this is strictly redundant, lol, I'm not building back up to episodes here.\n",
    "# TODO refactor to be less silly\n",
    "test_dict.update(speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "857ffdc0-89ca-4c15-9b3b-4fc8f6fdb0c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GARAK': 7,\n",
       " 'BASHIR': 15,\n",
       " \"O'BRIEN\": 6,\n",
       " 'SISKO': 11,\n",
       " 'DAX': 2,\n",
       " 'KIRA': 2,\n",
       " 'TAHNA': 3}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
